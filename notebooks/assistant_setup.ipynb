{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from embedder.voyage import VoyageEmbedder\n",
    "embedder = VoyageEmbedder(api_key=os.getenv('VOYAGE_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Scraper\n",
    "\n",
    "Run the scraper for all the spiders from the `./scraper/` folder.\n",
    "\n",
    "Eg: to run the grad_school_info_spider\n",
    "`scrapy crawl grad_school_info_spider`\n",
    "\n",
    "The data will be accumulated inside the `data/<spider_name>` folder path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Doc Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_multiple_whitespaces(s):\n",
    "    return re.sub('\\s+', ' ', s)\n",
    "\n",
    "def remove_newlines(s):\n",
    "    s = s.replace('\\r\\n\\t', '')\n",
    "    s = s.replace('\\n', ' ')\n",
    "    s = s.replace('\\r', ' ')\n",
    "    s = s.replace('\\t', ' ')\n",
    "    #remove multiple whitespaces\n",
    "    s = remove_multiple_whitespaces(s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "metadata_path = glob(os.path.join(data_path, '*/**/*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/grad_school_info_spider/gradstudy.rutgers.edu/metadata.json',\n",
       " '../data/grad_school_info_spider/grad.admissions.rutgers.edu/metadata.json',\n",
       " '../data/grad_school_info_spider/rutgers.my.site.com/metadata.json',\n",
       " '../data/grad_school_info_spider/grad.rutgers.edu/metadata.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load content from all the markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 86.23it/s]\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for path in tqdm(metadata_path, total=len(metadata_path)):\n",
    "    #open json file\n",
    "    with open(path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    for filename, meta in metadata.items():\n",
    "        records.append({\n",
    "            'markdown': open(os.path.join('../data', filename), 'r').read(),\n",
    "            'url': meta['url'],\n",
    "            'title': meta['title'],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['markdown'] = data['markdown'].apply(remove_newlines)\n",
    "data['title'] = data['title'].apply(remove_newlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/markdowns.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Examine the token distribution in these documents*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_tokens'] = data['markdown'].apply(lambda x: embedder.count_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      102.000000\n",
       "mean      3440.911765\n",
       "std       2125.939485\n",
       "min        885.000000\n",
       "10%       2033.700000\n",
       "25%       2500.000000\n",
       "50%       2961.000000\n",
       "75%       3725.750000\n",
       "90%       4647.300000\n",
       "max      18395.000000\n",
       "Name: num_tokens, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_tokens'].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102 [00:00<?, ?it/s]/Users/arao/Library/Caches/pypoetry/virtualenvs/sgs-chatbot-LQF_GuE7-py3.10/lib/python3.10/site-packages/voyageai/client.py:38: UserWarning: The `model` argument is not specified and defaults to voyage-2. It will be a required argument in the future. We recommend to specify the model when using this function. Please see https://docs.voyageai.com/docs/embeddings for the list of latest models provided by Voyage AI.\n",
      "  warnings.warn(\n",
      "100%|██████████| 102/102 [00:36<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "records = data.to_dict(orient='records')\n",
    "updated_records = []\n",
    "for record in tqdm(records, total=len(records)):\n",
    "    updated_records.append({\n",
    "        'url': record['url'],\n",
    "        'title': record['title'],\n",
    "        'markdown': record['markdown'],\n",
    "        'num_tokens': record['num_tokens'],\n",
    "        'embeddings': embedder.embed(record['markdown'])\n",
    "    })\n",
    "\n",
    "data = pd.DataFrame(updated_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet('../data/embeddings.parquet', engine='pyarrow', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Ingestion to DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgs-chatbot-LQF_GuE7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
